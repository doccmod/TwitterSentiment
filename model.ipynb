{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: only using Apple data at the moment\n",
    "# unsure if its better to train per stock or all at once\n",
    "\n",
    "# Create dataframes for the tweets and prices \n",
    "tweet_df = pd.read_csv('csv/aapl.csv')\n",
    "price_df = pd.read_csv('csv/aapl_price.csv') # Retrieved from https://www.nasdaq.com/market-activity/stocks/aapl/historical\n",
    "\n",
    "# Rename the date column so they match between dataframes\n",
    "tweet_df.rename(columns = {'DATE': 'date'}, inplace = True)\n",
    "price_df.rename(columns = {'Date' : 'date'}, inplace = True)\n",
    "\n",
    "# Merge the dataframes based on the date column\n",
    "merged_df = pd.merge(tweet_df, price_df, on = 'date')\n",
    "\n",
    "# Save to csv for double checking\n",
    "#merged_df.to_csv('merged.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the sentiment score and stock price to something more maliable\n",
    "merged_df.rename(columns = {'TEXTBLOB_POLARITY': 'sentimentScore', 'Close/Last': 'stockPrice'}, inplace = True)\n",
    "\n",
    "# Create the final dataframe with only the sentiment score and stock price\n",
    "final_df = merged_df[['sentimentScore', 'stockPrice']]\n",
    "\n",
    "# Remove the $ sign in stock price, and convert both columns to float64 (may be redundant)\n",
    "final_df.loc[:, 'stockPrice'] = final_df['stockPrice'].str.replace('$', '')\n",
    "final_df.loc[:, 'sentimentScore'] = pd.to_numeric(final_df['sentimentScore'])\n",
    "final_df.loc[:, 'stockPrice'] = pd.to_numeric(final_df['stockPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this scales the values for supposedly better allignment, but may not give intended results \n",
    "\n",
    "# Create the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale both values \n",
    "final_df.loc[:, ['sentimentScore', 'stockPrice']] = scaler.fit_transform(final_df[['sentimentScore', 'stockPrice']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into X and y\n",
    "X = final_df['sentimentScore'].values\n",
    "y = final_df['stockPrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: reshaping needs to be done properly according to accurate LSTM inputs\n",
    "# sorry, first time using tensorflow and LSTMs\n",
    "# see https://towardsdatascience.com/implementation-differences-in-lstm-layers-tensorflow-vs-pytorch-77a31d742f74\n",
    "\n",
    "# Reshape X\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Split X and Y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# More reshaping that needs to be fixed\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Main\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: model can be changed\n",
    "# right now there's 3 layers of LSTM and Dropout however better results may be achived with different LSTM layering\n",
    "\n",
    "# LSTM Model with Dropout and Dense\n",
    "model = Sequential([\n",
    "    Input(shape = X_train.shape[1:]),\n",
    "    LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1:], 1)),\n",
    "    Dropout(0.2), \n",
    "    LSTM(units = 50, return_sequences = True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units = 50),\n",
    "    Dropout(0.2),\n",
    "    Dense(units = 1)\n",
    "])\n",
    "\n",
    "# Use the Adam optimizer\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'mean_sqaured_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# NOTE: does not work due to improper shaping\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# see above link in NOTES\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model with verbose settings for debugging\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate and print the loss\u001b[39;00m\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Main\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Main\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# NOTE: does not work due to improper shaping\n",
    "# see above link in NOTES\n",
    "\n",
    "# Fit the model with verbose settings for debugging\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32, verbose = 1)\n",
    "\n",
    "# Calculate and print the loss\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
