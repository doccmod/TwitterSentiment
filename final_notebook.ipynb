{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df, columns):\n",
    "    all_years = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "    all_months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    all_days = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "    all_days_of_week = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "    one_hot_encoded_df = pd.get_dummies(df, columns = columns)\n",
    "    one_hot_encoded_df = one_hot_encoded_df.reindex(columns=[f'year_{year}' for year in all_years], fill_value=0)\n",
    "    one_hot_encoded_df = one_hot_encoded_df.reindex(columns=[f'month_{month}' for month in all_months], fill_value=0)\n",
    "    one_hot_encoded_df = one_hot_encoded_df.reindex(columns=[f'day_{day}' for day in all_days], fill_value=0)\n",
    "    one_hot_encoded_df = one_hot_encoded_df.reindex(columns=[f'day_of_week_{day_of_week}' for day_of_week in all_days_of_week], fill_value=0)\n",
    "\n",
    "    print(one_hot_encoded_df.head())\n",
    "    print(df.head())\n",
    "\n",
    "    new_dataframe = pd.concat([df, one_hot_encoded_df], axis=1)\n",
    "\n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all stocks\n",
    "stocks = ['aapl', 'amzn', 'googl', 'msft', 'tsla']\n",
    "\n",
    "# Get rid of annoying errors that don't matter\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Create the scaler\n",
    "sentimentScaler = MinMaxScaler()\n",
    "stockScaler = MinMaxScaler()\n",
    "\n",
    "# Create the datasets from the csvs\n",
    "# Could use a lot of work to reduce loc but it doesn't matter for marks\n",
    "def dataFrames(stock):\n",
    "\n",
    "    # Create dataframes for the tweets and prices \n",
    "    tweet_df = pd.read_csv('csv/' + stock + '.csv')\n",
    "    tweet_1_df = pd.read_csv('csv/' + stock + '_1.csv')\n",
    "    price_df = pd.read_csv('csv/' + stock + '_price.csv')\n",
    "\n",
    "    # Rename the date column so they match between dataframes\n",
    "    tweet_df.rename(columns = {'DATE': 'date'}, inplace = True)\n",
    "    tweet_1_df.rename(columns = {'Date': 'date'}, inplace = True)\n",
    "    price_df.rename(columns = {'Date' : 'date', 'Close/Last': 'stockPrice'}, inplace = True)\n",
    "\n",
    "    # Rename the score column so they match between dataframes\n",
    "    tweet_df.rename(columns = {'TEXTBLOB_POLARITY': 'sentimentScore'}, inplace = True)\n",
    "    tweet_1_df.rename(columns = {'score': 'sentimentScore'}, inplace = True)\n",
    "\n",
    "    # Remove the $ sign in stock price, and convert columns to float64 (may be redundant)\n",
    "    price_df['stockPrice'] = price_df['stockPrice'].str.replace('$', '')\n",
    "    tweet_df['sentimentScore'] = pd.to_numeric(tweet_df['sentimentScore'])\n",
    "    tweet_1_df['sentimentScore'] = pd.to_numeric(tweet_1_df['sentimentScore'])\n",
    "    price_df['stockPrice'] = pd.to_numeric(price_df['stockPrice'])\n",
    "\n",
    "    # Convert the dates to pd datetime\n",
    "    price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "    tweet_df['date'] = pd.to_datetime(tweet_df['date'], dayfirst = True)\n",
    "    tweet_1_df['date'] = pd.to_datetime(tweet_1_df['date'])\n",
    "\n",
    "    # Reduce to only nessicary columns\n",
    "    tweet_df = tweet_df[['date', 'sentimentScore']]\n",
    "    tweet_1_df = tweet_1_df[['date', 'sentimentScore']]\n",
    "    price_df = price_df[['date', 'stockPrice']]\n",
    "\n",
    "    # Merge the dataframes based on the date column\n",
    "    merged_1_df = pd.merge(tweet_df, price_df, on = 'date')\n",
    "    merged_2_df = pd.merge(tweet_1_df, price_df, on = 'date')\n",
    "    merged_df = pd.merge(merged_1_df, merged_2_df, how = 'outer')\n",
    "\n",
    "    # Drop all duplicates\n",
    "    final_df = merged_df.drop_duplicates()\n",
    "\n",
    "    # Convert date to specific variables\n",
    "    final_df['year'] = final_df['date'].dt.year\n",
    "    final_df['month'] = final_df['date'].dt.month\n",
    "    final_df['day'] = final_df['date'].dt.day\n",
    "    final_df['day_of_week'] = final_df['date'].dt.dayofweek\n",
    "\n",
    "    # One-hot encoding, should be done for all for financial data\n",
    "    #final_df = oneHotEncode(final_df, ['year', 'month', 'day', 'day_of_week'])\n",
    "    #final_df = pd.get_dummies(final_df, columns = ['year', 'month', 'day', 'day_of_week'])\n",
    "\n",
    "    # Drop the original date column\n",
    "    final_df = final_df.drop(columns = ['date'])\n",
    "\n",
    "    # Save to csv for double checking\n",
    "    #final_df.to_csv('final_' + stock + '.csv', index = False)\n",
    "\n",
    "    # Scale the numerical values\n",
    "    final_df[['sentimentScore']] = sentimentScaler.fit_transform(final_df[['sentimentScore']])\n",
    "    final_df[['stockPrice']] = stockScaler.fit_transform(final_df[['stockPrice']])\n",
    "\n",
    "    # Split into X and y\n",
    "    X = final_df.drop(columns = ['stockPrice'])\n",
    "    y = final_df['stockPrice']\n",
    "\n",
    "    # Split the datasets into training and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    '''# Reshape the datasets\n",
    "    X_train_reshaped = reshape_data(X_train)\n",
    "    X_test_reshaped = reshape_data(X_test)'''\n",
    "\n",
    "    # NOTE: Sequence length (1) could be improved by making one of the commented functions above work.\n",
    "    X_train_reshaped = np.reshape(X_train, (-1, 1, X_train.shape[1]))\n",
    "    X_test_reshaped = np.reshape(X_test, (-1,  1, X_test.shape[1]))\n",
    "    y_train_array = y_train.values\n",
    "    y_test_array = y_test.values\n",
    "\n",
    "    # Return the training and test datasets\n",
    "    return X_train_reshaped, X_test_reshaped, y_train_array, y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl X_train shape: (21542, 1, 5)\n",
      "aapl y_train shape: (21542,)\n",
      "amzn X_train shape: (19976, 1, 5)\n",
      "amzn y_train shape: (19976,)\n",
      "googl X_train shape: (16819, 1, 5)\n",
      "googl y_train shape: (16819,)\n",
      "msft X_train shape: (14943, 1, 5)\n",
      "msft y_train shape: (14943,)\n",
      "tsla X_train shape: (20452, 1, 5)\n",
      "tsla y_train shape: (20452,)\n"
     ]
    }
   ],
   "source": [
    "all_data = {}  # Dictionary to hold data for all stocks\n",
    "\n",
    "for stock in stocks:\n",
    "    # Run the 'dataFrames' function for each stock\n",
    "    data = dataFrames(stock)\n",
    "    \n",
    "    # Store the datasets in the dictionary\n",
    "    all_data[stock] = {\n",
    "        'X_train': data[0],\n",
    "        'X_test': data[1],\n",
    "        'y_train': data[2],\n",
    "        'y_test': data[3]\n",
    "    }\n",
    "\n",
    "    # Print the shapes of X_train and y_train for the current stock\n",
    "    print(f\"{stock} X_train shape: {data[0].shape}\")\n",
    "    print(f\"{stock} y_train shape: {data[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 4ms/step - loss: 0.0489\n",
      "aapl Test Loss:  0.04890572279691696\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0973\n",
      "amzn Test Loss:  0.09730158746242523\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0657\n",
      "googl Test Loss:  0.06572912633419037\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.0738\n",
      "msft Test Loss:  0.0737779513001442\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0376\n",
      "tsla Test Loss:  0.03758905455470085\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionary to store the models for each stock\n",
    "models = {}\n",
    "\n",
    "for stock, datasets in all_data.items():\n",
    "    X_train = datasets['X_train']\n",
    "    y_train = datasets['y_train']\n",
    "    X_test = datasets['X_test']\n",
    "    y_test = datasets['y_test']\n",
    "    \n",
    "    # Define the model for current stock\n",
    "    model = Sequential([\n",
    "        Input(shape=X_train.shape[1:]),\n",
    "        LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1:], 1)),\n",
    "        Dropout(0.2), \n",
    "        LSTM(units=50, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=50),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "\n",
    "    # Convert data type of input arrays to float32\n",
    "    X_train = X_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "\n",
    "    # Compile model using the Adam optimizer\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "    # Ensure that X_train and y_train have the same number of samples (if necessary)\n",
    "    X_train = X_train[:len(y_train)]\n",
    "\n",
    "    # Fit the model with verbose settings for debugging\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate the model and print the loss\n",
    "    loss = model.evaluate(X_test, y_test)\n",
    "    print(f\"{stock} Test Loss: \", loss)\n",
    "\n",
    "    # Store the model in the dictionary\n",
    "    models[stock] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl Random Forest Test Loss:  4.1968745959621414e-10\n",
      "aapl Linear Regression Test Loss:  0.011016191169306345\n",
      "aapl Decision Tree Test Loss:  1.9007839717704197e-32\n",
      "amzn Random Forest Test Loss:  1.1315437327411813e-09\n",
      "amzn Linear Regression Test Loss:  0.010219437240305293\n",
      "amzn Decision Tree Test Loss:  3.912598012761351e-32\n",
      "googl Random Forest Test Loss:  5.083253809348119e-09\n",
      "googl Linear Regression Test Loss:  0.006389820932366614\n",
      "googl Decision Tree Test Loss:  3.846647740672896e-32\n",
      "msft Random Forest Test Loss:  1.955834244360713e-09\n",
      "msft Linear Regression Test Loss:  0.00498345298212116\n",
      "msft Decision Tree Test Loss:  7.520586315893814e-33\n",
      "tsla Random Forest Test Loss:  8.65813642465698e-09\n",
      "tsla Linear Regression Test Loss:  0.02937480932458805\n",
      "tsla Decision Tree Test Loss:  1.2126277193947334e-32\n"
     ]
    }
   ],
   "source": [
    "for stock, datasets in all_data.items():\n",
    "    X_train = datasets['X_train']\n",
    "    y_train = datasets['y_train']\n",
    "    X_test = datasets['X_test']\n",
    "    y_test = datasets['y_test']\n",
    "\n",
    "    # Flatten X data for compatibility with RandomForest, Linear Regression, and Decision Tree\n",
    "    num_samples, timesteps, num_features = X_train.shape\n",
    "    X_train_2d = X_train.reshape(num_samples, timesteps * num_features)\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], timesteps * num_features)\n",
    "\n",
    "    # Store processed data\n",
    "    all_data[stock] = (X_train_2d, X_test_2d, y_train, y_test)\n",
    "\n",
    "# Initialize dictionaries for models and their performances\n",
    "rf_models = {}\n",
    "rf_losses = {}\n",
    "lr_models = {}\n",
    "lr_losses = {}\n",
    "dt_models = {}\n",
    "dt_losses = {}\n",
    "\n",
    "for stock, (X_train_2d, X_test_2d, y_train, y_test) in all_data.items():\n",
    "    # RandomForestRegressor\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_2d, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test_2d)\n",
    "    rf_loss = mean_squared_error(y_test, rf_predictions)\n",
    "    rf_models[stock] = rf_model\n",
    "    rf_losses[stock] = rf_loss\n",
    "    print(f\"{stock} Random Forest Test Loss: \", rf_loss)\n",
    "\n",
    "    # Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train_2d, y_train)\n",
    "    lr_predictions = lr_model.predict(X_test_2d)\n",
    "    lr_loss = mean_squared_error(y_test, lr_predictions)\n",
    "    lr_models[stock] = lr_model\n",
    "    lr_losses[stock] = lr_loss\n",
    "    print(f\"{stock} Linear Regression Test Loss: \", lr_loss)\n",
    "    \n",
    "    # Decision Tree Regressor\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_model.fit(X_train_2d, y_train)\n",
    "    dt_predictions = dt_model.predict(X_test_2d)\n",
    "    dt_loss = mean_squared_error(y_test, dt_predictions)\n",
    "    dt_models[stock] = dt_model\n",
    "    dt_losses[stock] = dt_loss\n",
    "    print(f\"{stock} Decision Tree Test Loss: \", dt_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl Gaussian Naive Bayes Test Accuracy:  0.9658373561084292\n",
      "amzn Gaussian Naive Bayes Test Accuracy:  0.9983983983983984\n",
      "googl Gaussian Naive Bayes Test Accuracy:  0.9938168846611177\n",
      "msft Gaussian Naive Bayes Test Accuracy:  0.9352248394004282\n",
      "tsla Gaussian Naive Bayes Test Accuracy:  0.9822022296107961\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries for GaussianNB models and their accuracies\n",
    "gaussian_nb_models = {}\n",
    "gaussian_nb_accuracies = {}\n",
    "\n",
    "# Label encoder to convert continuous labels to discrete integers\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for stock, (X_train_2d, X_test_2d, y_train, y_test) in all_data.items():\n",
    "    # Convert continuous labels to discrete integers\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    # Define and initialize the Gaussian Naive Bayes model\n",
    "    bayes_model = GaussianNB()\n",
    "\n",
    "    # Fit the model with the reshaped 2D training data and encoded labels\n",
    "    bayes_model.fit(X_train_2d, y_train_encoded)\n",
    "\n",
    "    # Make predictions on the reshaped 2D test data\n",
    "    bayes_predictions = bayes_model.predict(X_test_2d)\n",
    "\n",
    "    # Calculate and print the accuracy for the test set predictions\n",
    "    accuracy = accuracy_score(y_test_encoded, bayes_predictions)\n",
    "    print(f\"{stock} Gaussian Naive Bayes Test Accuracy: \", accuracy)\n",
    "\n",
    "    # Store the model and its accuracy\n",
    "    gaussian_nb_models[stock] = bayes_model\n",
    "    gaussian_nb_accuracies[stock] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(10, 1)\n",
      "[[18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "true_price = {}\n",
    "final_tweets = {}\n",
    "symbols = ['AAPL', 'AMZN', 'GOOGL', 'MSFT', 'TSLA']\n",
    "\n",
    "def predictData(symbol, stock = 'aapl'):\n",
    "\n",
    "    # Get the model for the stock\n",
    "    current_price_data = [[168.45], [168.45], [168.45], [168.45], [168.45], [168.45], [168.45], [168.45], [168.45], [168.45]]\n",
    "    current_price_data = pd.DataFrame(current_price_data, columns=['stockPrice'])\n",
    "    current_price_data['stockPrice'] = pd.to_numeric(current_price_data['stockPrice'])\n",
    "    current_price_data['stockPrice'] = stockScaler.transform(current_price_data[['stockPrice']])\n",
    "    \n",
    "    # Get the true price\n",
    "    y_true = current_price_data.values\n",
    "    y_true = stockScaler.inverse_transform(y_true)\n",
    "    print(y_true.shape)\n",
    "\n",
    "    # Get the current tweets\n",
    "    current_tweets = pd.read_csv('csv/output.csv')\n",
    "    current_tweets.rename(columns = {'Date': 'date'}, inplace = True)\n",
    "    current_tweets.rename(columns = {'Sentiment': 'sentimentScore'}, inplace = True)\n",
    "    \n",
    "    # Remove the $ sign in stock price, and convert columns to float64 (may be redundant)\n",
    "    sentiment_mapping = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
    "    current_tweets['sentimentScore'] = current_tweets['sentimentScore'].map(sentiment_mapping)\n",
    "    current_tweets = current_tweets[['date', 'sentimentScore']]\n",
    "    current_tweets['sentimentScore'] = pd.to_numeric(current_tweets['sentimentScore'])\n",
    "    current_tweets['sentimentScore'] = sentimentScaler.transform(current_tweets[['sentimentScore']])\n",
    "\n",
    "    # Convert the dates to pd datetime\n",
    "    current_tweets['date'] = pd.to_datetime(current_tweets['date'])\n",
    "    current_tweets['year'] = current_tweets['date'].dt.year\n",
    "    current_tweets['month'] = current_tweets['date'].dt.month\n",
    "    current_tweets['day'] = current_tweets['date'].dt.day\n",
    "    current_tweets['day_of_week'] = current_tweets['date'].dt.dayofweek\n",
    "\n",
    "    # Final changes\n",
    "    X = current_tweets.drop(columns = ['date'])\n",
    "    X = np.reshape(X, (-1, 1, X.shape[1]))\n",
    "    X = X.astype('float32')\n",
    "\n",
    "    # Use old data\n",
    "    '''X = all_data['aapl'][1]\n",
    "    X = np.reshape(X, (-1, 1, X.shape[1]))\n",
    "    print(X.shape)'''\n",
    "\n",
    "    y_test = stockScaler.inverse_transform(model.predict(X))\n",
    "    print(y_test.shape)\n",
    "    predictions[stock] = y_test\n",
    "    true_price[stock] = y_true\n",
    "    final_tweets[stock] = X\n",
    "\n",
    "# Predict for each stock\n",
    "'''for stock in stocks:\n",
    "    print(f\"Predictions for {stock}:\")\n",
    "    predictData(stock)'''\n",
    "\n",
    "predictData('AAPL')\n",
    "\n",
    "print(predictions['aapl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentimentScore    year  month  day  day_of_week\n",
      "0        0.678082  2024.0    4.0  8.0          0.0\n",
      "1        0.609589  2024.0    4.0  8.0          0.0\n",
      "2        0.746575  2024.0    4.0  8.0          0.0\n",
      "3        0.609589  2024.0    4.0  8.0          0.0\n",
      "4        0.678082  2024.0    4.0  8.0          0.0\n",
      "5        0.609589  2024.0    4.0  8.0          0.0\n",
      "6        0.678082  2024.0    4.0  8.0          0.0\n",
      "7        0.746575  2024.0    4.0  8.0          0.0\n",
      "8        0.678082  2024.0    4.0  8.0          0.0\n",
      "9        0.746575  2024.0    4.0  8.0          0.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     24\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mplotPredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_price\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maapl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maapl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_tweets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maapl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[102], line 7\u001b[0m, in \u001b[0;36mplotPredictions\u001b[1;34m(y_true, y_pred, X)\u001b[0m\n\u001b[0;32m      4\u001b[0m X_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_df, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentimentScore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_df)\n\u001b[1;32m----> 7\u001b[0m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m      8\u001b[0m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(y_pred_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m X\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentimentScore\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "def plotPredictions(y_true, y_pred, X): \n",
    "\n",
    "    X_df = X.reshape(-1, X.shape[-1])\n",
    "    X_df = pd.DataFrame(X_df, columns = ['sentimentScore', 'year', 'month', 'day', 'day_of_week'])\n",
    "    print(X_df)\n",
    "\n",
    "    X['date'] = X['year'].astype(str) + '-' + X['month'].astype(str) + '-' + X['day'].astype(str)\n",
    "    X['date'] = pd.to_datetime(y_pred_merged['date'])\n",
    "\n",
    "    X.drop(columns = ['year', 'month', 'day', 'day_of_week', 'sentimentScore'], inplace = True)\n",
    "\n",
    "    y_pred_merged = pd.merge(X, y_pred, left_index=True, right_index=True)\n",
    "    y_true_merged = pd.merge(X, y_true, left_index=True, right_index=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_pred_merged, y_pred_merged['stockPrice'], label = 'Predicted Price', color = 'red')\n",
    "    plt.plot(y_true_merged, y_true_merged['stockPrice'], label = 'True Price', color = 'blue')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.title('Predicted vs True Stock Price')\n",
    "    plt.legend\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotPredictions(true_price['aapl'], predictions['aapl'], final_tweets['aapl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for aapl:\n",
      "MSE: 101.68148798978098\n",
      "MAE: 10.083723914793632\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_and_plot_metrics(y_true, y_pred):\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "\n",
    "    # Plot metrics\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"MSE\")\n",
    "    plt.bar(['MSE'], [mse])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"MAE\")\n",
    "    plt.bar(['MAE'], [mae])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Calculate and plot metrics for each stock\n",
    "'''for stock in stocks:\n",
    "    print(f\"Metrics for {stock}:\")\n",
    "    y_true = true_price[stock]\n",
    "    y_pred = predictions[stock]\n",
    "    calculate_and_plot_metrics(y_true, y_pred)'''\n",
    "\n",
    "print(f\"Metrics for aapl:\")\n",
    "y_true = true_price['aapl']\n",
    "y_pred = predictions['aapl']\n",
    "calculate_and_plot_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]\n",
      " [18.379349]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {8} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Find the optimal threshold\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_scores)\n\u001b[1;32m----> 8\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m optimal_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(tpr \u001b[38;5;241m-\u001b[39m fpr)\n\u001b[0;32m     10\u001b[0m optimal_threshold \u001b[38;5;241m=\u001b[39m thresholds[optimal_idx]\n",
      "File \u001b[1;32mc:\\School\\4442B\\TwitterSentiment\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\School\\4442B\\TwitterSentiment\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1108\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1007\u001b[0m     {\n\u001b[0;32m   1008\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m ):\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \n\u001b[0;32m   1021\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\School\\4442B\\TwitterSentiment\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:834\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    831\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m y_score[nonzero_weight_mask]\n\u001b[0;32m    832\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[nonzero_weight_mask]\n\u001b[1;32m--> 834\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[43m_check_pos_label_consistency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# make y_true a boolean vector\u001b[39;00m\n\u001b[0;32m    837\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m==\u001b[39m pos_label\n",
      "File \u001b[1;32mc:\\School\\4442B\\TwitterSentiment\\lib\\site-packages\\sklearn\\utils\\validation.py:2454\u001b[0m, in \u001b[0;36m_check_pos_label_consistency\u001b[1;34m(pos_label, y_true)\u001b[0m\n\u001b[0;32m   2443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   2444\u001b[0m     classes\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2451\u001b[0m     )\n\u001b[0;32m   2452\u001b[0m ):\n\u001b[0;32m   2453\u001b[0m     classes_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[1;32m-> 2454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2455\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true takes value in \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclasses_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m and pos_label is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified: either make y_true take value in \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0, 1} or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m-1, 1} or pass pos_label explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2458\u001b[0m     )\n\u001b[0;32m   2459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2460\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true takes value in {8} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "# Assuming y_true, X_test are defined, and model is trained\n",
    "\n",
    "# Predict scores\n",
    "y_scores = y_pred\n",
    "\n",
    "# Find the optimal threshold\n",
    "print(y_scores)\n",
    "fpr, tpr, thresholds = roc_curve(y_true.astype(int), y_scores)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Convert the predicted values to binary based on the optimal threshold\n",
    "y_pred_binary_optimal = np.where(y_scores > optimal_threshold, 1, 0)\n",
    "\n",
    "# Calculate metrics using the binary values with the optimal threshold\n",
    "accuracy_opt = accuracy_score(y_true.astype(int), y_pred_binary_optimal)\n",
    "precision_opt = precision_score(y_true.astype(int), y_pred_binary_optimal)\n",
    "recall_opt = recall_score(y_true.astype(int), y_pred_binary_optimal)\n",
    "f1_opt = f1_score(y_true.astype(int), y_pred_binary_optimal)\n",
    "roc_auc_opt = roc_auc_score(y_true.astype(int), y_scores)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(f\"Precision: {precision_opt}\")\n",
    "print(f\"Recall: {recall_opt}\")\n",
    "print(f\"F1 Score: {f1_opt}\")\n",
    "print(f\"ROC AUC: {roc_auc_opt}\")\n",
    "\n",
    "# Plot metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "values_opt = [accuracy_opt, precision_opt, recall_opt, f1_opt, roc_auc_opt]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(metrics, values_opt, color='skyblue')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('Performance Metrics with Optimized Threshold')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterSentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
